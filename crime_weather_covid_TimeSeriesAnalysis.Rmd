---
title: "The influence of weather and a pandemic on crime"
output:
  html_document:
    df_print: paged
---
```{r Markdown cheatsheet, echo=FALSE}
# echo=FALSE prevents code, but not the results from appearing in the rendered file
# eval=TRUE evaluates the code and includes the results
# results='hide' hides the results but displays the code
```


### Install packages (if required)

```{r install packages, eval=FALSE} 
# set eval=TRUE if running script for the first time
if(!require("ggseas")) install.packages("ggseas")
if(!require("forecast")) install.packages("forecast")
if(!require("data.table")) install.packages("data.table")
if(!require("knitr")) install.packages("knitr")
if(!require("bigrquery")) install.packages("bigrquery")
if(!require("devtools")) install.packages("devtools") 
if(!require("tsibble")) install.packages("tsibble")
if(!require("fable")) install.packages("fable")  # forecasting package of the tidyverse family
# devtools::install_github("rstats-db/bigrquery", force = TRUE)
```

### Load packages

```{r eval=TRUE, results='hide'}
library(bigrquery)
library(ggplot2)
library(tidyr)
library(dplyr)
library(lubridate) # handle date information
library(readr) # read txt file with credentials
#library(ggseas)
#library(forecast)
#library(data.table)
library(fable)
```

### Retrieve Google Cloud credentials
Retrieve Google Cloud project ID, which I store in an external file (not uploaded to github).
```{r set up credentials, }
# Set Google Cloud project ID here
project_name <- read_file("./GC_credentials.txt")
```


## Retrieve data with date information

```{r setup request}
sql <- "
SELECT 
  iucr,
  primary_type,
  description, 
  date
FROM `bigquery-public-data.chicago_crime.crime` 
"
```

TODO: Cache locally and only fetch additional (recent) data.

```{r execute SQL call}
# Execute the query and store the result
counts_day <- query_exec(sql, project = project_name, use_legacy_sql = FALSE, max_pages = Inf)
str(counts_day)
```

```{r write out csv}
write.csv(counts_day, "counts_day.csv", row.names = FALSE)
```

```{r}
counts_day <- read.csv("counts_day.csv")
head(counts_day)
# format as date and drop the time part
counts_day$date <- as.Date(ymd_hms(counts_day$date))
head(counts_day)
```


In the dataframe, each row stands for one offense of a particular type, at a particular time. We add a column of "counts", that for now is always one. This fascilitates summing up rows (e.g., by day) later on.
```{r add colum}
counts_day$count <- rep(1,nrow(counts_day))
# sort by ascending date
counts_day <- counts_day %>% arrange(date)
```

```{r aggregate counts per day}
# group by day (across offense types)
counts_day <- tibble(counts_day)

daily_counts <- test %>%
  group_by(date) %>%
  summarize(counts = sum(count))
head(daily_counts)
```

## tsibble: time-sensitive tibble
1. Index is a variable with inherent ordering from past to present.
2. Key is a set of variables that define observational units over time.
3. Each observation should be uniquely identified by index and key.
4. Each observational unit should be measured at a common interval, if regularly spaced.
```{r time-aware tibble}
# turn into time-sensitive tibble
# works like a normal tibble but tracks time (set by index)
daily_counts <- as_tsibble(daily_counts, index=date) %>% arrange(date)
```


## Time series analysis

Is this a multiplicative or additive time series?

Each time series has three components: 
1) trend
2) seasonality
3) error

# simple plot using the fable package
daily_counts %>% autoplot(counts)



## arima model
## use auto.arima to choose ARIMA terms
fit <- auto.arima(daily_ts)
## forecast for next 60 time points
fore <- forecast(fit, h = 60)
## plot it
plot(fore)
